{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "525b813a-faf9-4d4d-bb23-a9729c78a66c",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3125691a-5a25-4ccd-8ba6-d361c7d587b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from copy import deepcopy\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc42b628-da4b-4f2d-8215-90e1e6be291e",
   "metadata": {},
   "source": [
    "# Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c33e328-6896-4b2b-b352-72aa14840c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_images(data: list, rmv_ids: list)->list:\n",
    "    data_new = deepcopy(data)\n",
    "    \n",
    "    # Remove images\n",
    "    data_new['images'] = [x for x in data['images'] if x['id'] not in rmv_ids]\n",
    "    \n",
    "    # Remove bbox annotations\n",
    "    data_new['annotations'] = [x for x in data['annotations'] if x['image_id'] not in rmv_ids]\n",
    "    \n",
    "    print(f\"# of images in data before: [{len(data['images'])}] >> after: [{len(data_new['images'])}]\")\n",
    "    print(f\"# of bboxes in data before: [{len(data['annotations'])}] >> after: [{len(data_new['annotations'])}]\")\n",
    "    \n",
    "    return data_new\n",
    "\n",
    "\n",
    "def save_json(data: dict, file_nm: str, dir_path='../../dataset'):\n",
    "    with open(os.path.join(data_dir, file_nm), 'w') as outfile:\n",
    "        json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a49ff8-28c5-49c9-be61-46a9ab1294d1",
   "metadata": {},
   "source": [
    "# Load train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fdf6cd-af49-41c2-9512-3caf9b2294ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../dataset' # data_dir 경로\n",
    "\n",
    "annot_train = '../../dataset/cv_train_1.json' # Multilabel K-Fold 방식으로 분리된 train set의 annotation\n",
    "annot_valid = '../../dataset/cv_val_1.json' # Multilabel K-Fold 방식으로 분리된 validation set의 annotation\n",
    "\n",
    "with open(annot_train) as f:\n",
    "    data_train = json.load(f)\n",
    "    \n",
    "with open(annot_valid) as f:\n",
    "    data_valid = json.load(f)\n",
    "   \n",
    "coco_train = COCO(annot_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c1afdc-54b8-4093-9a59-8865920f4231",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_list = []\n",
    "\n",
    "for image_id in coco_train.getImgIds():\n",
    "        \n",
    "    image_info = coco_train.loadImgs(image_id)[0]\n",
    "    annotation_id = coco_train.getAnnIds(imgIds=image_info['id'])\n",
    "    annotation_info_list = coco_train.loadAnns(annotation_id)\n",
    "        \n",
    "    file_name = image_info['file_name']\n",
    "        \n",
    "    for annotation in annotation_info_list:\n",
    "        gt_list.append([file_name,\n",
    "                        annotation['id'],\n",
    "                        annotation['category_id'],\n",
    "                       float(annotation['bbox'][0]),\n",
    "                       float(annotation['bbox'][0]) + float(annotation['bbox'][2]),\n",
    "                       float(annotation['bbox'][1]),\n",
    "                       (float(annotation['bbox'][1]) + float(annotation['bbox'][3]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63e13e2-049a-4bfc-82f6-52f11976a535",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f290945b-f979-4803-ac65-726c6de96651",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(gt_list, columns=['img_id', 'annot_id', 'label', 'x1', 'x2', 'y1', 'y2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec64e16-981d-4dce-ad31-93764eb91464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get box size\n",
    "train_df['area'] = train_df.apply(lambda x: (x['y2']-x['y1'])*(x['x2']-x['x1']), axis=1)\n",
    "\n",
    "# Get box center point\n",
    "train_df['cent_x'] = (train_df.x2+train_df.x1)/2\n",
    "train_df['cent_y'] = (train_df.y2+train_df.y1)/2\n",
    "\n",
    "# Get width and height\n",
    "train_df['width'] = train_df.x2-train_df.x1\n",
    "train_df['height'] = train_df.y2-train_df.y1\n",
    "\n",
    "# Get width and height ratio\n",
    "train_df['height/width'] = train_df.height/train_df.width \n",
    "\n",
    "# Get bbox size\n",
    "train_df['diagonal'] = (train_df.width**2 + train_df.height**2)**0.5\n",
    "\n",
    "# Get label nm\n",
    "LABEL_NAME = [\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \n",
    "              \"Glass\", \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\"]\n",
    "map_label_2_nm = {idx: nm for idx, nm in zip(range(len(LABEL_NAME)), LABEL_NAME)}\n",
    "train_df['label_nm'] = train_df.label.map(map_label_2_nm)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e85939b-90b3-49a6-92ed-29b888529112",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Remove images with excessively many bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36f30c2-9151-4595-b2fd-68072f1dcf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get box per image upper threshold for outlier check\n",
    "box_per_img = train_df.img_id.value_counts()\n",
    "print(box_per_img.describe())\n",
    "\n",
    "q1_box_per_img, q3_box_per_img = np.percentile(box_per_img, [25, 75])\n",
    "upper_box_per_img = q3_box_per_img + (q3_box_per_img-q1_box_per_img)*1.5\n",
    "print(f'Outlier threshold for box per image: {upper_box_per_img}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eb2ab0-2fd1-46e1-a7c7-506520041a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image ids for removing\n",
    "out_box_per_img_list = sorted([int(x[-8:-4]) for x in box_per_img[box_per_img > upper_box_per_img].index])\n",
    "out_box_per_img_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108a7289-133b-45d5-a1c9-7b7be700b675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an outlier removed dataset\n",
    "data_train_v6 = remove_images(data_train, out_box_per_img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6048eff-7898-47c4-a085-a56785923bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(save_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2f3456-a066-422e-9702-e6df8a40e4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save new dataset version 6\n",
    "save_json(data_train_v6, 'cv_train_1_v6.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
