{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: adamp in /opt/conda/envs/detection/lib/python3.7/site-packages (0.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install wandb --upgrade\n",
    "!pip install adamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import torch\n",
    "# faster rcnn model이 포함된 library\n",
    "import torchvision\n",
    "\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb\n",
    "\n",
    "from map_boxes import mean_average_precision_for_boxes\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "from adamp import AdamP\n",
    "\n",
    "from CosineAnnealingWarmUpRestarts import CosineAnnealingWarmUpRestarts\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold \n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcv-3-bitcoin\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실행 후 url을 클릭하면 API key가 나오는데 복붙하시면 됩니다!!\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    '''\n",
    "      data_dir: data가 존재하는 폴더 경로\n",
    "      transforms: data transform (resize, crop, Totensor, etc,,,)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, annotation, data_dir, transforms=None):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        # coco annotation 불러오기 (coco API)\n",
    "        self.coco = COCO(annotation)\n",
    "        self.predictions = {\n",
    "            \"images\": self.coco.dataset[\"images\"].copy(),\n",
    "            \"categories\": self.coco.dataset[\"categories\"].copy(),\n",
    "            \"annotations\": None\n",
    "        }\n",
    "        self.transforms = transforms\n",
    "        self.img_ids = self.coco.getImgIds()\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        image_id = self.coco.getImgIds(imgIds=self.img_ids[index])\n",
    "\n",
    "        image_info = self.coco.loadImgs(image_id)[0]\n",
    "        \n",
    "        image = cv2.imread(os.path.join(self.data_dir, image_info['file_name']))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=image_info['id'])\n",
    "        anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "        boxes = np.array([x['bbox'] for x in anns])\n",
    "\n",
    "        # boxex (x_min, y_min, x_max, y_max)\n",
    "        boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n",
    "        boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n",
    "        \n",
    "        # torchvision faster_rcnn은 label=0을 background로 취급\n",
    "        # class_id를 1~10으로 수정 \n",
    "        labels = np.array([x['category_id']+1 for x in anns]) \n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        \n",
    "        areas = np.array([x['area'] for x in anns])\n",
    "        areas = torch.as_tensor(areas, dtype=torch.float32)\n",
    "                                \n",
    "        is_crowds = np.array([x['iscrowd'] for x in anns])\n",
    "        is_crowds = torch.as_tensor(is_crowds, dtype=torch.int64)\n",
    "\n",
    "        target = {'boxes': boxes, 'labels': labels, 'image_id': torch.tensor([index]), 'area': areas,\n",
    "                  'iscrowd': is_crowds}\n",
    "\n",
    "        # transform\n",
    "        if self.transforms:\n",
    "            sample = {\n",
    "                'image': image,\n",
    "                'bboxes': target['boxes'],\n",
    "                'labels': labels\n",
    "            }\n",
    "            sample = self.transforms(**sample)\n",
    "            image = sample['image']\n",
    "            target['boxes'] = torch.tensor(sample['bboxes'], dtype=torch.float32)\n",
    "\n",
    "        return image, target, image_id\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.coco.getImgIds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidDataset(Dataset):\n",
    "    '''\n",
    "      data_dir: data가 존재하는 폴더 경로\n",
    "      transforms: data transform (resize, crop, Totensor, etc,,,)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, annotation, data_dir):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        # coco annotation 불러오기 (coco API)\n",
    "        self.coco = COCO(annotation)\n",
    "        \n",
    "        self.img_ids = self.coco.getImgIds()\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        image_id = self.coco.getImgIds(imgIds=self.img_ids[index])\n",
    "\n",
    "        image_info = self.coco.loadImgs(image_id)[0]\n",
    "        \n",
    "        image = cv2.imread(os.path.join(self.data_dir, image_info['file_name']))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=image_info['id'])\n",
    "        anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "        image = torch.tensor(image, dtype=torch.float32).permute(2,0,1)\n",
    "\n",
    "        return image\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.coco.getImgIds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform():\n",
    "    return A.Compose([\n",
    "        A.Resize(256, 256),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.RandomBrightness(p=0.5),\n",
    "        A.RandomFog(fog_coef_lower=0.3, fog_coef_upper=1, alpha_coef=0.08, always_apply=False, p=0.5),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
    "\n",
    "\n",
    "def get_valid_transform():\n",
    "    return A.Compose([\n",
    "        A.Resize(256, 256),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Averager:\n",
    "    def __init__(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0\n",
    "\n",
    "    def send(self, value):\n",
    "        self.current_total += value\n",
    "        self.iterations += 1\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        if self.iterations == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1.0 * self.current_total / self.iterations\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(num_epochs, train_data_loader, valid_data_loader, valid_data_loader_4_map, annotation_valid, optimizer, model, device, name, scheduler):\n",
    "    #####----------------------------------------------------------------####\n",
    "    wandb.watch(model)    \n",
    "    #####----------------------------------------------------------------####\n",
    "    best_loss = 1000\n",
    "    best_val_loss = 1000\n",
    "    best_val_map = 0\n",
    "    loss_hist = Averager()\n",
    "    val_loss_hist = Averager()\n",
    "    for epoch in range(num_epochs):\n",
    "        # train loop\n",
    "        loss_hist.reset()\n",
    "        model.train()\n",
    "\n",
    "        for images, targets, image_ids in tqdm(train_data_loader):\n",
    "\n",
    "            # gpu 계산을 위해 image.to(device)\n",
    "            images = list(image.float().to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            # calculate loss\n",
    "            loss_dict = model(images, targets)\n",
    "\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            loss_value = losses.item()\n",
    "\n",
    "            loss_hist.send(loss_value)\n",
    "\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # valid loop    \n",
    "        with torch.no_grad():\n",
    "            val_loss_hist.reset()\n",
    "            \n",
    "            for val_images, val_targets, image_ids in tqdm(valid_data_loader, \n",
    "                                                       desc='Calculating validation results'):\n",
    "                val_images = list(val_image.float().to(device) for val_image in val_images)\n",
    "                val_targets = [{k: v.to(device) for k, v in t.items()} for t in val_targets]\n",
    "                \n",
    "                val_loss_dict = model(val_images, val_targets)\n",
    "                \n",
    "                val_losses = sum(val_loss for val_loss in val_loss_dict.values())\n",
    "                val_loss_value = val_losses.item()\n",
    "                \n",
    "                val_loss_hist.send(val_loss_value)\n",
    "                \n",
    "        #================ mAP calculation ===================\n",
    "            score_threshold = 0.5\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            # predict\n",
    "            outputs = evaluate_fn(valid_data_loader_4_map, model, device)\n",
    "            prediction_strings = []\n",
    "            file_names = []\n",
    "\n",
    "            coco = COCO(annotation_valid)\n",
    "            img_ids = coco.getImgIds()\n",
    "\n",
    "            # Validation prediction 파일 생성\n",
    "            for i, output in enumerate(outputs):\n",
    "                prediction_string = ''\n",
    "                image_info = coco.loadImgs(coco.getImgIds(imgIds=img_ids[i]))[0]\n",
    "                for box, score, label in zip(output['boxes'], output['scores'], output['labels']):\n",
    "                    if score > score_threshold: \n",
    "                        # label[1~10] -> label[0~9]\n",
    "                        prediction_string += str(label-1) + ' ' + str(score) + ' ' + str(box[0]) + ' ' + str(\n",
    "                            box[1]) + ' ' + str(box[2]) + ' ' + str(box[3]) + ' '\n",
    "                prediction_strings.append(prediction_string)\n",
    "                file_names.append(image_info['file_name'])\n",
    "            submission = pd.DataFrame()\n",
    "            submission['PredictionString'] = prediction_strings\n",
    "            submission['image_id'] = file_names\n",
    "            submission.to_csv(f'./faster_rcnn_torchvision_valid_prediction.csv', index=None)\n",
    "\n",
    "\n",
    "            PRED_CSV = f'./faster_rcnn_torchvision_valid_prediction.csv'\n",
    "            LABEL_NAME = [\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \n",
    "                          \"Glass\", \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\"]\n",
    "\n",
    "            pred_df = pd.read_csv(PRED_CSV)\n",
    "\n",
    "            new_pred = []\n",
    "\n",
    "            file_names = pred_df['image_id'].values.tolist()\n",
    "            bboxes = pred_df['PredictionString'].values.tolist()\n",
    "\n",
    "#             for i, bbox in enumerate(bboxes):\n",
    "#                 if isinstance(bbox, float):\n",
    "#                     print(f'{file_names[i]} empty box')\n",
    "\n",
    "            for file_name, bbox in tqdm(zip(file_names, bboxes)):\n",
    "                boxes = np.array(str(bbox).split(' '))\n",
    "\n",
    "                if len(boxes) % 6 == 1:\n",
    "                    boxes = boxes[:-1].reshape(-1, 6)\n",
    "                elif len(boxes) % 6 == 0:\n",
    "                    boxes = boxes.reshape(-1, 6)\n",
    "                else:\n",
    "                    raise Exception('error', 'invalid box count')\n",
    "                for box in boxes:\n",
    "                    new_pred.append([file_name, box[0], box[1], float(box[2]), float(box[4]), float(box[3]), float(box[5])])\n",
    "\n",
    "\n",
    "            gt = []\n",
    "\n",
    "            for image_id in coco.getImgIds():  # GT의 image_id\n",
    "\n",
    "                image_info = coco.loadImgs(image_id)[0]    \n",
    "                annotation_id = coco.getAnnIds(imgIds=image_info['id'])\n",
    "                annotation_info_list = coco.loadAnns(annotation_id)  # return annotation information list\n",
    "\n",
    "                file_name = image_info['file_name']\n",
    "\n",
    "                for annotation in annotation_info_list:\n",
    "                    gt.append([file_name, annotation['category_id'],\n",
    "                            float(annotation['bbox'][0]),\n",
    "                            float(annotation['bbox'][0]) + float(annotation['bbox'][2]),\n",
    "                            float(annotation['bbox'][1]),\n",
    "                            (float(annotation['bbox'][1]) + float(annotation['bbox'][3]))])\n",
    "\n",
    "            val_mean_ap, val_average_precisions = mean_average_precision_for_boxes(gt, new_pred, iou_threshold=0.5)\n",
    "        #===================================\n",
    "                \n",
    "        scheduler.step()\n",
    "                \n",
    "        print(f\"Epoch #{epoch+1} loss: {loss_hist.value} || valid loss: {val_loss_hist.value} || valid mAP: {val_mean_ap}\")\n",
    "        # if val_loss.value < best_val_loss:\n",
    "        if val_mean_ap > best_val_map:\n",
    "            save_path = './checkpoints/faster_rcnn_torchvision_checkpoints_'+name+'.pth'\n",
    "            save_dir = os.path.dirname(save_path)\n",
    "            if not os.path.exists(save_dir):\n",
    "                os.makedirs(save_dir)\n",
    "                \n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            best_val_loss = val_loss_hist.value\n",
    "            best_val_map = val_mean_ap\n",
    "            print('Save model according to the renewed best validation mAP')\n",
    "        #####----------------------------------------------------------------####\n",
    "        wandb.log({\"train_loss\": loss_hist.value, \"valid_loss\": val_loss_hist.value, \"valid_mAP\": val_mean_ap}, step=epoch)\n",
    "        #####----------------------------------------------------------------####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fn(test_data_loader, model, device):\n",
    "    outputs = []\n",
    "    \n",
    "    for images in tqdm(test_data_loader):\n",
    "        # gpu 계산을 위해 image.to(device)\n",
    "        images = list(image.to(device) for image in images)\n",
    "        # print(len(images))  # 8\n",
    "        output = model(images)\n",
    "        # print(len(output))  # 8\n",
    "        for img,out in zip(images,output):\n",
    "            # print(len(out['boxes']))\n",
    "            all_boxes=[]\n",
    "            outputs.append({'boxes': out['boxes'].tolist(), 'scores': out['scores'].tolist(), 'labels': out['labels'].tolist()})\n",
    "    \n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임시로 만든 config라서 뭘 추가 하면 좋을 지 같이 얘기해보면 좋을 것 같습니다!!\n",
    "# config 안에 들어간 값들은 다 Wandb에 올라가서, 중요한 파라미터 들은 다 넣어야 할 것 같아요.\n",
    "config = {\n",
    "    'epochs': 30,\n",
    "    'batch_size':16,\n",
    "    'shuffle':False,\n",
    "    'num_workers': 0,\n",
    "    'lr': 0.001,\n",
    "    'weight_decay':0.0005,\n",
    "    'lr_decay_step':2,\n",
    "    'momentum':0.9,\n",
    "    'score_threshold': 0.025,\n",
    "    \"augmentation\": [\"RandomRotate90(p=0.5)\", \"RandomBrightness(p=0.5)\"],\n",
    "    \"scheduler\": 'CosineAnnealingWarmUpRestarts(T_0=6, T_mult=1, eta_max=0.02, T_up=2, gamma=0.5 )',\n",
    "    \"optimizer\": 'sgd'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(train_annot: str, valid_annot: str, name: str, config=None):\n",
    "    #####--------------------------------wandb 연결 및 config 지정-------------------------------------------------####\n",
    "    # project : 'project 이름' ,\n",
    "    # entity : '팀 이름'\n",
    "    wandb.init(project='daegun', entity='cv-3-bitcoin', config = config, reinit=True)\n",
    "    wandb.run.name = name  # 실험의 이름 지정\n",
    "    config = wandb.config\n",
    "    #####---------------------------------------------------------------------------------------------####\n",
    "    \n",
    "    # 데이터셋 불러오기\n",
    "    data_dir = '../../dataset' # data_dir 경로\n",
    "    annotation_train = os.path.join(data_dir, train_annot) # annotation 경로\n",
    "    annotation_valid = os.path.join(data_dir, valid_annot) # annotation 경로\n",
    "\n",
    "    train_dataset = CustomDataset(annotation_train, data_dir, get_train_transform()) \n",
    "    train_data_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=config.shuffle,\n",
    "        num_workers=config.num_workers,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    \n",
    "    valid_dataset = CustomDataset(annotation_valid, data_dir, get_valid_transform()) \n",
    "    valid_data_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=config.shuffle,\n",
    "        num_workers=config.num_workers,\n",
    "        collate_fn=collate_fn\n",
    "    )    \n",
    "    \n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    print(device)\n",
    "    \n",
    "    # torchvision model 불러오기\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    # model = torchvision.models.detection.ssd300_vgg16(pretrained=True)\n",
    "    num_classes = 11 # class 개수= 10 + background\n",
    "\n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    model.to(device)\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    \n",
    "    optimizer = torch.optim.SGD(params, lr=config.lr, momentum=config.momentum, weight_decay=config.weight_decay)\n",
    "    # optimizer = torch.optim.AdamW(params, lr=config.lr, weight_decay = config.weight_decay)\n",
    "    num_epochs = config.epochs\n",
    "    # scheduler = StepLR(optimizer, config.lr_decay_step, gamma=0.5)\n",
    "    # scheduler = CosineAnnealingLR(optimizer, T_max=6, eta_min=0)\n",
    "    scheduler = CosineAnnealingWarmUpRestarts(optimizer,T_0=6, T_mult=1, eta_max=0.02, T_up=2, gamma=0.5 )\n",
    "    # T_0 : 최초 주기값,\n",
    "    # T_mult는 주기가 반복되면서 최초 주기값에 비해 얼만큼 주기를 늘려나갈 것인지 스케일 값\n",
    "    # eta_max는 learning rate의 최댓값\n",
    "    # T_up은 Warm up 시 필요한 epoch 수를 지정하며 일반적으로 짧은 epoch 수를 지정\n",
    "    # gamma는 주기가 반복될수록 eta_max 곱해지는 스케일값\n",
    "\n",
    "    # scheduler = ReduceLROnPlateau(\n",
    "    #     optimizer,\n",
    "    #     factor=0.5,   # 학습률이 감소하는 요인입니다. new_lr = lr * factor.\n",
    "    #     patience=config.lr_decay_step,\n",
    "    #     threshold=0.001,  \n",
    "    #     verbose=True,  \n",
    "    #     min_lr=1e-4,  \n",
    "    #     threshold_mode=\"abs\",\n",
    "    # )\n",
    "        \n",
    "    valid_dataset_4_map = ValidDataset(annotation_valid, data_dir)\n",
    "    valid_data_loader_4_map = DataLoader(\n",
    "        valid_dataset_4_map,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=config.shuffle,\n",
    "        num_workers=config.num_workers\n",
    "    )\n",
    "    \n",
    "    # training\n",
    "    train_fn(num_epochs, train_data_loader, valid_data_loader, valid_data_loader_4_map, annotation_valid, optimizer, model, device, name, scheduler)\n",
    "    \n",
    "    #####--------------------------------calculate mAP------------------------------------------------------####\n",
    "#     score_threshold = 0.5\n",
    "\n",
    "#     model.eval()\n",
    "\n",
    "#     # predict\n",
    "#     outputs = evaluate_fn(valid_data_loader_4_map, model, device)\n",
    "#     prediction_strings = []\n",
    "#     file_names = []\n",
    "    \n",
    "#     coco = COCO(annotation_valid)\n",
    "#     img_ids = coco.getImgIds()\n",
    "    \n",
    "#     # submission 파일 생성\n",
    "#     for i, output in enumerate(outputs):\n",
    "#         prediction_string = ''\n",
    "#         image_info = coco.loadImgs(coco.getImgIds(imgIds=img_ids[i]))[0]\n",
    "#         for box, score, label in zip(output['boxes'], output['scores'], output['labels']):\n",
    "#             if score > config.score_threshold: \n",
    "#                 # label[1~10] -> label[0~9]\n",
    "#                 prediction_string += str(label-1) + ' ' + str(score) + ' ' + str(box[0]) + ' ' + str(\n",
    "#                     box[1]) + ' ' + str(box[2]) + ' ' + str(box[3]) + ' '\n",
    "#         prediction_strings.append(prediction_string)\n",
    "#         file_names.append(image_info['file_name'])\n",
    "#     submission = pd.DataFrame()\n",
    "#     submission['PredictionString'] = prediction_strings\n",
    "#     submission['image_id'] = file_names\n",
    "#     submission.to_csv(f'./faster_rcnn_torchvision_valid_submission_{name}.csv', index=None)\n",
    "    \n",
    "\n",
    "#     PRED_CSV = f'./faster_rcnn_torchvision_valid_submission_{name}.csv'\n",
    "#     LABEL_NAME = [\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \n",
    "#               \"Glass\", \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\"]\n",
    "\n",
    "#     pred_df = pd.read_csv(PRED_CSV)\n",
    "\n",
    "#     new_pred = []\n",
    "\n",
    "#     file_names = pred_df['image_id'].values.tolist()\n",
    "#     bboxes = pred_df['PredictionString'].values.tolist()\n",
    "    \n",
    "#     for i, bbox in enumerate(bboxes):\n",
    "#         if isinstance(bbox, float):\n",
    "#             print(f'{file_names[i]} empty box')\n",
    "\n",
    "#     for file_name, bbox in tqdm(zip(file_names, bboxes)):\n",
    "#         boxes = np.array(str(bbox).split(' '))\n",
    "    \n",
    "#         if len(boxes) % 6 == 1:\n",
    "#             boxes = boxes[:-1].reshape(-1, 6)\n",
    "#         elif len(boxes) % 6 == 0:\n",
    "#             boxes = boxes.reshape(-1, 6)\n",
    "#         else:\n",
    "#             raise Exception('error', 'invalid box count')\n",
    "#         for box in boxes:\n",
    "#             new_pred.append([file_name, box[0], box[1], float(box[2]), float(box[4]), float(box[3]), float(box[5])])\n",
    "\n",
    "\n",
    "#     gt = []\n",
    "\n",
    "#     for image_id in coco.getImgIds():  # GT의 image_id\n",
    "        \n",
    "#         image_info = coco.loadImgs(image_id)[0]    \n",
    "#         annotation_id = coco.getAnnIds(imgIds=image_info['id'])\n",
    "#         annotation_info_list = coco.loadAnns(annotation_id)  # return annotation information list\n",
    "        \n",
    "#         file_name = image_info['file_name']\n",
    "        \n",
    "#         for annotation in annotation_info_list:\n",
    "#             gt.append([file_name, annotation['category_id'],\n",
    "#                     float(annotation['bbox'][0]),\n",
    "#                     float(annotation['bbox'][0]) + float(annotation['bbox'][2]),\n",
    "#                     float(annotation['bbox'][1]),\n",
    "#                     (float(annotation['bbox'][1]) + float(annotation['bbox'][3]))])\n",
    "\n",
    "#     mean_ap, average_precisions = mean_average_precision_for_boxes(gt, new_pred, iou_threshold=0.5)\n",
    "\n",
    "#     wandb.log({\"mAP\": mean_ap})\n",
    "    wandb.run.save()\n",
    "    #####---------------------------------------------------------------------------------------------####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.12.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/opt/ml/detection/baseline/feature-scheduler-two-model/wandb/run-20220406_124230-s489esum</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cv-3-bitcoin/daegun/runs/s489esum\" target=\"_blank\">final-cube-82</a></strong> to <a href=\"https://wandb.ai/cv-3-bitcoin/daegun\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.20s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "cuda\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/230 [00:00<?, ?it/s]/opt/conda/envs/detection/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "100%|██████████| 230/230 [04:10<00:00,  1.09s/it]\n",
      "Calculating validation results:  29%|██▉       | 22/76 [00:18<00:45,  1.20it/s]"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main('cv_train_1.json', 'cv_val_1.json', 'run_test', config)\n",
    "    # main('cv_train_1_minor.json', 'cv_val_1_minor.json', 'minor', config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
